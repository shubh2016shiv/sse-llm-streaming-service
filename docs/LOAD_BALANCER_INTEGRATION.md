# Load Balancer Integration - Complete Educational Guide

## üìã Table of Contents

1. [Architecture Overview](#architecture-overview)
2. [Integration Points](#integration-points)
3. [Request Flow Walkthrough](#request-flow-walkthrough)
4. [Configuration Files](#configuration-files)
5. [Code Annotations](#code-annotations)
6. [Testing Load Distribution](#testing-load-distribution)
7. [Common Pitfalls](#common-pitfalls)

---

## Architecture Overview

### The Complete System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         USER's BROWSER                              ‚îÇ
‚îÇ                   http://localhost:3001                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚îÇ (1) HTTP Request
                         ‚îÇ     POST /api/v1/stream
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              PERFORMANCE DASHBOARD (React/Vite)                     ‚îÇ
‚îÇ                   Frontend Application                              ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  File: performance_dashboard/src/api.js                            ‚îÇ
‚îÇ  const API_BASE_URL = 'https://localhost/api/v1'  ‚Üê CRITICAL!     ‚îÇ
‚îÇ                                     ‚Üë                               ‚îÇ
‚îÇ                                     ‚îî‚îÄ This URL determines          ‚îÇ
‚îÇ                                        if load balancer is used     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚îÇ (2) HTTPS Request
                         ‚îÇ     https://localhost/api/v1/stream
                         ‚îÇ     ‚Üë
                         ‚îÇ     ‚îî‚îÄ Notice: Port 443 (implicit)
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    NGINX LOAD BALANCER                              ‚îÇ
‚îÇ                   (Docker Container)                                ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  Listens on: Port 80 (HTTP) and 443 (HTTPS)                       ‚îÇ
‚îÇ  Config: infrastructure/nginx/nginx.conf                           ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  upstream sse_backend {                                            ‚îÇ
‚îÇ      least_conn;  ‚Üê Uses "least connections" algorithm            ‚îÇ
‚îÇ      server app-1:8000;  ‚Üê Docker service name                    ‚îÇ
‚îÇ      server app-2:8000;                                            ‚îÇ
‚îÇ      server app-3:8000;                                            ‚îÇ
‚îÇ  }                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ              ‚îÇ              ‚îÇ
         ‚îÇ (3a) Proxy   ‚îÇ (3b) Proxy   ‚îÇ (3c) Proxy
         ‚îÇ 33% traffic  ‚îÇ 33% traffic  ‚îÇ 34% traffic
         ‚ñº              ‚ñº              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  FastAPI     ‚îÇ  ‚îÇ  FastAPI     ‚îÇ  ‚îÇ  FastAPI     ‚îÇ
‚îÇ  Instance 1  ‚îÇ  ‚îÇ  Instance 2  ‚îÇ  ‚îÇ  Instance 3  ‚îÇ
‚îÇ  (app-1)     ‚îÇ  ‚îÇ  (app-2)     ‚îÇ  ‚îÇ  (app-3)     ‚îÇ
‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ
‚îÇ  Port: 8000  ‚îÇ  ‚îÇ  Port: 8000  ‚îÇ  ‚îÇ  Port: 8000  ‚îÇ
‚îÇ  (internal)  ‚îÇ  ‚îÇ  (internal)  ‚îÇ  ‚îÇ  (internal)  ‚îÇ
‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ
‚îÇ  Connection  ‚îÇ  ‚îÇ  Connection  ‚îÇ  ‚îÇ  Connection  ‚îÇ
‚îÇ  Pool: 3/usr ‚îÇ  ‚îÇ  Pool: 3/usr ‚îÇ  ‚îÇ  Pool: 3/usr ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                 ‚îÇ                 ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                 ‚îÇ REDIS CLUSTER ‚îÇ
                 ‚îÇ  (Shared)     ‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Integration Points

### 1. **Frontend API Configuration** (UI ‚Üí Load Balancer)

**File**: `performance_dashboard/src/api.js`

**Purpose**: Configures where the React frontend sends API requests

**Critical Line**:
```javascript
const API_BASE_URL = import.meta.env.VITE_API_BASE_URL || 'https://localhost/api/v1';
                                                            ^^^^^^^^^^^^^^^^^^^^^^
                                                            THIS IS THE KEY!
```

**Why This Matters**:
- ‚úÖ `https://localhost/api/v1` ‚Üí Routes through NGINX (port 443) ‚Üí Load balanced
- ‚ùå `http://localhost:8000/api/v1` ‚Üí Bypasses NGINX ‚Üí Direct to single instance

**Visual Representation**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Frontend Request (from browser)                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                               ‚îÇ
         ‚ñº                               ‚ñº
    CORRECT URL                    WRONG URL
 https://localhost                http://localhost:8000
         ‚îÇ                               ‚îÇ
         ‚ñº                               ‚ñº
    ‚úÖ NGINX                        ‚ùå Bypasses NGINX
    Port 443                        Direct Connection
         ‚îÇ                               ‚îÇ
         ‚ñº                               ‚ñº
  Load Balanced                   Single Instance
  (3 instances)                   (No distribution)
```

---

### 2. **NGINX Configuration** (Load Balancer ‚Üí Backend)

**File**: `infrastructure/nginx/nginx.conf`

**Key Sections**:

#### Section A: Upstream Definition (Lines 296-402)
```nginx
upstream sse_backend {
    # LOAD BALANCING ALGORITHM
    # ------------------------
    # least_conn: Send request to server with fewest active connections
    # Perfect for long-lived SSE streaming connections
    least_conn;
    
    # BACKEND SERVERS
    # ---------------
    # Docker service names resolve to container IPs automatically
    server app-1:8000 max_fails=3 fail_timeout=30s;
    server app-2:8000 max_fails=3 fail_timeout=30s;
    server app-3:8000 max_fails=3 fail_timeout=30s;
    
    # CONNECTION POOLING
    # ------------------
    # Maintain 32 persistent connections to backend
    # Reduces latency by reusing TCP connections
    keepalive 32;
}
```

**How NGINX Knows Which Backend to Use**:
1. Client connects to NGINX
2. NGINX checks current connections to each backend
3. Selects backend with **fewest active connections**
4. Proxies request to selected backend
5. Maintains connection state for load balancing

#### Section B: HTTP to HTTPS Redirect (Lines 422-432)
```nginx
server {
    listen 80;  # HTTP port
    server_name _;
    
    # FORCE HTTPS
    # All HTTP requests automatically redirected to HTTPS
    return 301 https://$host$request_uri;
}
```

**Why This Matters**:
- Ensures all traffic uses HTTPS (encrypted)
- Security best practice
- Prevents accidental unencrypted connections

#### Section C: HTTPS Server Block (Lines 438-780)
```nginx
server {
    listen 443 ssl;  # HTTPS port
    http2 on;        # Enable HTTP/2 for better performance
    
    # SSL CERTIFICATES
    ssl_certificate /etc/nginx/ssl/localhost.crt;
    ssl_certificate_key /etc/nginx/ssl/localhost.key;
    
    # PROXY ALL REQUESTS TO BACKEND
    location / {
        # THIS IS WHERE LOAD BALANCING HAPPENS!
        proxy_pass http://sse_backend;  ‚Üê References upstream block
        
        # Preserve client information
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_set_header Host $host;
        
        # Enable streaming (critical for SSE)
        proxy_buffering off;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        
        # Long timeouts for streaming connections
        proxy_read_timeout 300s;  # 5 minutes
    }
}
```

**Request Flow Through NGINX**:
```
1. Client ‚Üí NGINX:443 (HTTPS)
2. NGINX decrypts SSL
3. NGINX selects backend (least_conn algorithm)
4. NGINX ‚Üí app-X:8000 (HTTP, internal network)
5. Backend processes request
6. NGINX ‚Üê app-X (streaming response)
7. Client ‚Üê NGINX (encrypted streaming response)
```

---

### 3. **Docker Compose Configuration** (Infrastructure ‚Üí Services)

**File**: `docker-compose.yml`

**Key Sections**:

#### Section A: NGINX Service (Lines 53-93)
```yaml
nginx:
  image: nginx:1.25-alpine
  container_name: sse-nginx
  
  # PORT MAPPING - CRITICAL!
  # -------------------------
  # Maps host ports to container ports
  # 80:80   ‚Üí HTTP  (redirects to HTTPS)
  # 443:443 ‚Üí HTTPS (main entry point)
  ports:
    - "80:80"     # Host port 80 ‚Üí Container port 80
    - "443:443"   # Host port 443 ‚Üí Container port 443
  
  # VOLUME MOUNTS
  # -------------
  # Mount configuration files into container
  volumes:
    - ./infrastructure/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    - ./infrastructure/nginx/ssl:/etc/nginx/ssl:ro
  
  # DEPENDENCIES
  # ------------
  # NGINX waits for at least one backend to be healthy
  depends_on:
    app-1:
      condition: service_healthy
  
  networks:
    - sse-network  # Same network as backend services
```

**Why Port Mapping Matters**:
```
                Outside World         Inside Container
                (Your Machine)        (Docker Network)
                ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ        ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Browser ‚Üí       localhost:443    ‚Üí    container:443  ‚Üí NGINX
                      ‚Üë                      ‚Üë
                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         Docker Port Mapping
```

#### Section B: Backend Services (Lines 96-230)
```yaml
# INSTANCE 1
app-1:
  build: .
  container_name: sse-app-1
  # NO PORT MAPPING! Not exposed to host
  # Only accessible via Docker network
  networks:
    - sse-network  # Same network as NGINX
  
# INSTANCE 2
app-2:
  build: .
  container_name: sse-app-2
  networks:
    - sse-network
  
# INSTANCE 3
app-3:
  build: .
  container_name: sse-app-3
  networks:
    - sse-network
```

**Critical Observation**:
- Backend services have **NO port mapping** to host
- Only accessible via Docker internal network
- NGINX can reach them via service names (`app-1`, `app-2`, `app-3`)
- Host machine **CANNOT** directly access them

**Network Isolation**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Host Machine (Your Computer)                    ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ  Browser can access:                            ‚îÇ
‚îÇ  ‚úÖ localhost:443 (NGINX)                       ‚îÇ
‚îÇ  ‚ùå app-1:8000 (not exposed)                    ‚îÇ
‚îÇ  ‚ùå app-2:8000 (not exposed)                    ‚îÇ
‚îÇ  ‚ùå app-3:8000 (not exposed)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚îÇ Docker Port Mapping (443:443)
                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Docker Network (sse-network)                    ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  nginx   ‚îÇ   ‚îÇ  app-1   ‚îÇ   ‚îÇ  app-2   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  :443    ‚îÇ   ‚îÇ  :8000   ‚îÇ   ‚îÇ  :8000   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ       ‚îÇ              ‚îÇ              ‚îÇ           ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ         Internal communication only             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Request Flow Walkthrough

### Example: Load Tester Sends 10 Concurrent Requests

**Step 1: Frontend Initiates Request**

**File**: `performance_dashboard/src/components/LoadTester.jsx`

```javascript
// Line 77
await fetchEventSource(`${API_BASE_URL}/stream`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
        query: "Write a short poem about performance testing.",
        model: "gpt-3.5-turbo",
        provider: "fake",
        stream: true
    }),
    // ... SSE event handlers
});
```

**What Happens**:
```
API_BASE_URL = 'https://localhost/api/v1'
Full URL = 'https://localhost/api/v1/stream'
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
              Goes to NGINX port 443
```

---

**Step 2: NGINX Receives Requests**

**NGINX Log**:
```nginx
127.0.0.1 - - [09/Dec/2025:17:14:05 +0000] "POST /api/v1/stream HTTP/1.1" ...
```

**Internal Processing**:
```nginx
# NGINX evaluates upstream block
upstream sse_backend {
    least_conn;
    server app-1:8000;  # Current connections: 0
    server app-2:8000;  # Current connections: 0
    server app-3:8000;  # Current connections: 0
}

# First 3 requests:
Request 1 ‚Üí app-1 (connections: 0 ‚Üí 1)
Request 2 ‚Üí app-2 (connections: 0 ‚Üí 1)
Request 3 ‚Üí app-3 (connections: 0 ‚Üí 1)

# Next 3 requests (all backends have 1 connection):
Request 4 ‚Üí app-1 (connections: 1 ‚Üí 2)
Request 5 ‚Üí app-2 (connections: 1 ‚Üí 2)
Request 6 ‚Üí app-3 (connections: 1 ‚Üí 2)

# Next 3 requests:
Request 7 ‚Üí app-1 (connections: 2 ‚Üí 3)
Request 8 ‚Üí app-2 (connections: 2 ‚Üí 3)
Request 9 ‚Üí app-3 (connections: 2 ‚Üí 3)

# 10th request (all backends have 3 connections):
Request 10 ‚Üí app-1 (connections: 3 ‚Üí attempts 4)
```

---

**Step 3: Backend Processes Requests**

**Backend Log** (app-1):
```json
{"stage": "CP.1", "user_id": "192.168.1.16", "event": "Attempting to acquire connection"}
{"stage": "CP.1.4", "user_connections": 1, "event": "Connection acquired"}
{"stage": "5.2", "event": "Starting stream"}
... (streaming response)
```

**Connection Pool Check**:
```python
# src/core/resilience/connection_pool_manager.py

async def acquire_connection(self, user_id: str, thread_id: str):
    # Check global limit
    if total_count >= 10000:
        raise ConnectionPoolExhaustedError()  # 503
    
    # Check per-user limit PER INSTANCE
    if user_count >= 3:  # ‚Üê This is per instance!
        raise UserConnectionLimitError()  # 429
    
    # Reserve connection
    await self._increment_counts(user_id, thread_id)
```

---

**Step 4: Distribution Summary**

With **load balancing**:
```
User sends 10 requests
‚îú‚îÄ app-1 accepts 3 ‚úÖ (200 OK - streaming)
‚îú‚îÄ app-2 accepts 3 ‚úÖ (200 OK - streaming)
‚îú‚îÄ app-3 accepts 3 ‚úÖ (200 OK - streaming)
‚îî‚îÄ app-1 rejects 1 ‚ùå (429 - user pool exhausted)

Result: 9 successful, 1 rejected
Total capacity: 3 √ó 3 = 9 connections per user
```

Without **load balancing** (direct to single instance):
```
User sends 10 requests
‚îî‚îÄ Local dev accepts 3 ‚úÖ (200 OK - streaming)
   ‚îî‚îÄ Rejects 7 ‚ùå (429 - user pool exhausted)

Result: 3 successful, 7 rejected
Total capacity: 3 connections per user
```

---

## Configuration Files Summary

### File Structure
```
SSE/
‚îú‚îÄ‚îÄ performance_dashboard/
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îî‚îÄ‚îÄ api.js                     ‚Üê Frontend API URL (CRITICAL!)
‚îÇ
‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îú‚îÄ‚îÄ nginx/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nginx.conf                 ‚Üê Load balancer config
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ssl/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ localhost.crt          ‚Üê SSL certificate
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ localhost.key          ‚Üê SSL private key
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ manage.py                      ‚Üê Infrastructure startup script
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml                 ‚Üê Service orchestration
‚îÇ
‚îî‚îÄ‚îÄ src/
    ‚îî‚îÄ‚îÄ core/
        ‚îî‚îÄ‚îÄ resilience/
            ‚îî‚îÄ‚îÄ connection_pool_manager.py  ‚Üê Per-instance limits
```

### Configuration Matrix

| File | Purpose | Load Balancing Impact |
|------|---------|----------------------|
| **`api.js`** | Frontend API URL | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **CRITICAL** - Determines if NGINX is used |
| **`nginx.conf`** | Load balancer rules | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Defines distribution algorithm |
| **`docker-compose.yml`** | Service deployment | ‚≠ê‚≠ê‚≠ê‚≠ê Port mappings and networking |
| **`connection_pool_manager.py`** | Per-instance limits | ‚≠ê‚≠ê‚≠ê Enforces limits on each backend |

---

## Code Annotations

### Frontend: `performance_dashboard/src/api.js`

```javascript
// ===========================================================================
// LOAD BALANCER INTEGRATION POINT
// ===========================================================================
// This URL determines the entire request routing:
//
// Option 1: https://localhost/api/v1 (RECOMMENDED)
// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
// Flow: Browser ‚Üí NGINX:443 ‚Üí app-1/app-2/app-3:8000
// Result: Load balanced across 3 instances
// Capacity: 9 concurrent connections per user (3 √ó 3)
//
// Option 2: http://localhost:8000/api/v1 (DEVELOPMENT ONLY)
// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
// Flow: Browser ‚Üí Local FastAPI:8000
// Result: Direct connection, bypasses NGINX entirely
// Capacity: 3 concurrent connections per user
//
const API_BASE_URL = import.meta.env.VITE_API_BASE_URL || 'https://localhost/api/v1';
```

### NGINX: `infrastructure/nginx/nginx.conf`

```nginx
# ===========================================================================
# UPSTREAM BACKEND POOL
# ===========================================================================
# Defines the pool of backend servers that NGINX can forward requests to.
# NGINX automatically distributes traffic across these servers using the
# configured load balancing algorithm.

upstream sse_backend {
    # LOAD BALANCING ALGORITHM: least_conn
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Routes new requests to the server with the fewest active connections.
    # Perfect for long-lived SSE streaming connections because:
    # - Prevents overloading any single instance
    # - Maintains even distribution as connections come and go
    # - Better than round-robin for varying connection durations
    least_conn;
    
    # BACKEND SERVER POOL
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Docker service names (app-1, app-2, app-3) resolve automatically
    # via Docker's internal DNS to container IP addresses
    server app-1:8000 max_fails=3 fail_timeout=30s;
    server app-2:8000 max_fails=3 fail_timeout=30s;
    server app-3:8000 max_fails=3 fail_timeout=30s;
}

# ===========================================================================
# HTTPS SERVER - MAIN ENTRY POINT
# ===========================================================================
server {
    listen 443 ssl;
    
    location / {
        # LOAD BALANCING HAPPENS HERE!
        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        # proxy_pass forwards requests to the upstream block defined above.
        # NGINX automatically selects which backend server to use based on
        # the least_conn algorithm.
        proxy_pass http://sse_backend;
        
        # Preserve client information for backend
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}
```

### Backend: `src/core/resilience/connection_pool_manager.py`

```python
class ConnectionPoolManager:
    """
    IMPORTANT: This connection pool is PER INSTANCE!
    
    With load balancing:
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    - Each of 3 instances has separate pool
    - Each pool allows 3 connections per user
    - Total capacity: 3 √ó 3 = 9 connections per user
    
    Without load balancing:
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    - Single instance has one pool
    - Pool allows 3 connections per user
    - Total capacity: 3 connections per user
    """
    
    def __init__(self, max_per_user: int = 3):
        self.max_per_user = max_per_user  # Per user, per instance
```

---

## Testing Load Distribution

### Manual Test

**Step 1: Verify NGINX is Running**
```bash
docker-compose ps nginx
```

**Expected Output**:
```
NAME        IMAGE              STATUS                   PORTS
sse-nginx   nginx:1.25-alpine  Up X minutes (healthy)   0.0.0.0:80->80/tcp, 0.0.0.0:443->443/tcp
```

**Step 2: Send Test Request Through NGINX**
```bash
curl -k https://localhost/api/v1/health
```

**Expected**:
```json
{"status": "healthy", "redis": "connected", "timestamp": "..."}
```

**Step 3: Monitor Backend Logs**
```bash
# Terminal 1: app-1 logs
docker logs sse-app-1 -f

# Terminal 2: app-2 logs
docker logs sse-app-2 -f

# Terminal 3: app-3 logs
docker logs sse-app-3 -f
```

**Step 4: Run Load Test**

From Performance Dashboard:
- Set concurrency: 10
- Set total requests: 30
- Click "Run Load Test"

**Expected Distribution**:
```
app-1 logs: ~10 requests (33%)
app-2 logs: ~10 requests (33%)
app-3 logs: ~10 requests (33%)
```

---

## Common Pitfalls

### ‚ùå Pitfall 1: Wrong API URL

**Symptom**:
```
All requests go to single instance
429 errors after only 3 concurrent connections
Load test capacity limited to 3
```

**Cause**:
```javascript
// WRONG: Bypasses NGINX
const API_BASE_URL = 'http://localhost:8000/api/v1';
```

**Fix**:
```javascript
// CORRECT: Routes through NGINX
const API_BASE_URL = 'https://localhost/api/v1';
```

---

### ‚ùå Pitfall 2: NGINX Not Running

**Symptom**:
```
ERR_CONNECTION_REFUSED when accessing https://localhost
```

**Diagnosis**:
```bash
docker-compose ps nginx
# Shows: nginx is not running or restarting
```

**Fix**:
```bash
# Check logs for errors
docker logs sse-nginx

# Common issue: Missing SSL certificates
# Solution: Certificates auto-generated by manage.py

# Restart infrastructure
python infrastructure/manage.py start
```

---

### ‚ùå Pitfall 3: Backend Not Reachable from NGINX

**Symptom**:
```
502 Bad Gateway from NGINX
NGINX logs show: upstream connect failed
```

**Diagnosis**:
```bash
# Check if backends are running
docker-compose ps app-1 app-2 app-3
```

**Fix**:
```bash
# Start all services
python infrastructure/manage.py start --all

# Verify backends are healthy
docker-compose ps
```

---

### ‚ùå Pitfall 4: SSL Certificate Issues

**Symptom**:
```
NGINX shows: cannot load certificate
Browser shows: ERR_SSL_PROTOCOL_ERROR
```

**Fix**:
```bash
# Certificates are auto-generated by manage.py
python infrastructure/manage.py start

# Verify certificates exist
ls infrastructure/nginx/ssl/
# Should show: localhost.crt, localhost.key
```

---

## Quick Reference

### ‚úÖ Correct Setup Checklist

- [ ] NGINX running: `docker-compose ps nginx` shows healthy
- [ ] 3 backends running: `docker-compose ps app-1 app-2 app-3`
- [ ] API URL uses HTTPS: `https://localhost/api/v1`
- [ ] SSL certificates exist: `ls infrastructure/nginx/ssl/`
- [ ] Performance dashboard accessible: `http://localhost:3001`

### üöÄ Quick Start Commands

```bash
# Full production setup
python infrastructure/manage.py start --all

# Verify load balancer
curl -k https://localhost/api/v1/health

# Monitor distribution
docker logs sse-app-1 -f &
docker logs sse-app-2 -f &
docker logs sse-app-3 -f &

# Run load test from dashboard
# http://localhost:3001
```

### üìä Expected Results

**Single Instance (Wrong Setup)**:
- Capacity: 3 connections per user
- All requests to one instance
- 70% failure rate with 10 concurrent requests

**Load Balanced (Correct Setup)**:
- Capacity: 9 connections per user (3 √ó 3)
- Requests distributed evenly
- 10% failure rate with 10 concurrent requests
- 3x better performance

---

**Created**: 2025-12-09  
**Last Updated**: 2025-12-09  
**Status**: ‚úÖ Complete - Ready for Production
